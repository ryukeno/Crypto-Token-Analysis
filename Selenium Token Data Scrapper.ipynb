{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium scraping TokenData.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get the data from TokenData.io which is a website that lists the Initial Coin Offering we want to analyze.\n",
    "Initial Coin Offering (ICO) are similiar to Initial Project Offering (IPO), but the funding is done in cryptocurrencies and the investment stages takes place differently you can find more information about this in the README.md file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "from random import random\n",
    "import logging\n",
    "import pandas as pd\n",
    "import lxml.html #Faster than Beatuiful Soup\n",
    "from lxml import etree\n",
    "\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Scraping Tokens and Coins')\n",
    "parser.add_argument('min_USD_Raised', metavar='min_cap', type=int, nargs='?', default=0,\n",
    "                   help='minimum market cap [usd] for currency to be scraped (default: scrape all)')\n",
    "parser.add_argument('max_date', metavar='max_date', type=str, nargs='?', default=\"Dec 2015\",\n",
    "                   help='Get all coin founded after this data. Example: Dec 2015, (default: scrape all)')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# Configuration\n",
    "timestamp_0 = 1367174841000\n",
    "timestamp_1 = int(round(time.time() * 1000))\n",
    "logging.basicConfig(\n",
    "    filename=\"logging.log\", \n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s:%(name)s:%(message)s',\n",
    "    datefmt='%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "BASE_URL = \"https://www.tokendata.io\"\n",
    "\n",
    "countRequested = 0\n",
    "interReqTime = 23\n",
    "lastReqTime = None\n",
    "\n",
    "def htmlRequest(targetURL):\n",
    "    global countRequested\n",
    "    global lastReqTime\n",
    "    if lastReqTime is not None and time.time() - lastReqTime < interReqTime:\n",
    "        timeToSleep = random()*(interReqTime-time.time()+lastReqTime)*2\n",
    "        logging.info(\"Sleeping for {0} seconds before request.\".format(timeToSleep))\n",
    "        time.sleep(timeToSleep)\n",
    "\n",
    "    option = webdriver.ChromeOptions()\n",
    "    option.add_argument('--incognito')\n",
    "\n",
    "    browser = webdriver.Chrome(executable_path='/Users/ironhackberlin/chromedriver', chrome_options=option)\n",
    "    browser.get(targetURL)\n",
    "    wait = WebDriverWait(browser, 10)\n",
    "    rows = wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//*[@id='sample_1']/tbody/tr\")))\n",
    "\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        datum = {}\n",
    "        info = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        datum[\"name\"] = info[1].text\n",
    "        try:\n",
    "            datum['usd_raised'] = float(info[2].text.strip().replace(\",\", \"\")[1:])\n",
    "        except:\n",
    "            datum['usd_raised'] = 0\n",
    "\n",
    "        datum['month'] = info[3].text\n",
    "\n",
    "        try:\n",
    "            datum['token_sale_price'] = float(info[4].text.strip().replace(\",\", \"\")[1:])\n",
    "        except:\n",
    "            datum['token_sale_price'] = 0\n",
    "        try:\n",
    "            datum['current_token_price'] = float(info[5].text.strip().replace(\",\", \"\")[1:])\n",
    "        except:\n",
    "            datum['current_token_price'] = 0\n",
    "\n",
    "        datum['token_return'] = info[6].text \n",
    "        datum['eth_return'] = info[7].text \n",
    "        datum['btc_return'] = info[8].text \n",
    "        datum['token/eth_return'] = info[9].text \n",
    "        datum['token/btc_return'] = info[10].text\n",
    "\n",
    "        if args.min_USD_Raised < datum['usd_raised']:\n",
    "            data.append(datum)\n",
    "\n",
    "    print(rows[0].find_elements(By.TAG_NAME, \"td\")[1].text)\n",
    "    print(rows[len(rows)-1].find_elements(By.TAG_NAME, \"td\")[1].text)\n",
    "\n",
    "    count = 0\n",
    "    while count < 10:\n",
    "        previousFirst = rows[0].find_elements(By.TAG_NAME, \"td\")[1].text\n",
    "        previousLast = rows[len(rows)-1].find_elements(By.TAG_NAME, \"td\")[1].text\n",
    "\n",
    "        step = int(len(rows)-15) \n",
    "        browser.execute_script(\"return arguments[0].scrollIntoView(true);\", rows[step])\n",
    "        #wait for the browser to load after scroll\n",
    "        time.sleep(1)\n",
    "\n",
    "        rows = wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//*[@id='sample_1']/tbody/tr\")))\n",
    "\n",
    "        print(len(rows))\n",
    "        print(rows[0].find_elements(By.TAG_NAME, \"td\")[1].text)\n",
    "        print(rows[len(rows)-1].find_elements(By.TAG_NAME, \"td\")[1].text)\n",
    "        currentFirst = rows[0].find_elements(By.TAG_NAME, \"td\")[1].text\n",
    "        currentLast = rows[len(rows)-1].find_elements(By.TAG_NAME, \"td\")[1].text\n",
    "        if previousLast != currentLast:\n",
    "            overlappingIndex = 0\n",
    "            #find overlapping\n",
    "            for index in range(0,len(rows)):\n",
    "                currentName = rows[index].find_elements(By.TAG_NAME, \"td\")[1].text\n",
    "                if previousLast == currentName:\n",
    "                    overlappingIndex = index\n",
    "                    break;\n",
    "\n",
    "            for index in range(overlappingIndex+1, len(rows)):\n",
    "                datum = {}\n",
    "                info = rows[index].find_elements(By.TAG_NAME, \"td\")\n",
    "                datum[\"name\"] = info[1].text\n",
    "                try:\n",
    "                    datum['usd_raised'] = float(info[2].text.strip().replace(\",\", \"\")[1:])\n",
    "                except:\n",
    "                    datum['usd_raised'] = 0\n",
    "                datum['month'] = info[3].text\n",
    "                try:\n",
    "                    datum['token_sale_price'] = float(info[4].text.strip().replace(\",\", \"\")[1:])\n",
    "                except:\n",
    "                    datum['token_sale_price'] = 0\n",
    "                try:\n",
    "                    datum['current_token_price'] = float(info[5].text.strip().replace(\",\", \"\")[1:])\n",
    "                except:\n",
    "                    datum['current_token_price'] = 0\n",
    "\n",
    "                datum['token_return'] = info[6].text \n",
    "                datum['eth_return'] = info[7].text \n",
    "                datum['btc_return'] = info[8].text \n",
    "                datum['token/eth_return'] = info[9].text \n",
    "                datum['token/btc_return'] = info[10].text \n",
    "                # print(info[1].text)\n",
    "                if args.min_USD_Raised < datum['usd_raised']:\n",
    "                    data.append(datum)\n",
    "\n",
    "        else:\n",
    "            break\n",
    "        count += 1\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def scrapeAdvanceDataList():\n",
    "    URL = \"{0}/{1}\".format(BASE_URL, 'advanced')\n",
    "    data = htmlRequest(URL)\n",
    "    return data\n",
    "\n",
    "def filterTimeFrom(df):\n",
    "    dataString = args.max_date\n",
    "    print(dataString)\n",
    "    number = args.max_date[:len(args.max_date)-1]\n",
    "    suffix = args.max_date[-1].upper()\n",
    "    if number.isdigit(): \n",
    "        number = int(num)\n",
    "    else:\n",
    "        logging.info(\"invalid max_date\")\n",
    "        sys.exit()\n",
    "    if suffix.isdigit():\n",
    "        logging.info(\"invalid max_date\")\n",
    "        sys.exit()\n",
    "\n",
    "    if suffix == \"D\":\n",
    "        d = datetime.timedelta(day=number)\n",
    "    else:\n",
    "        logging.info(\"invalid string. Please retry with Y,M,D only.\")\n",
    "        sys.exit()\n",
    "\n",
    "    threeMonth = df['time'].iloc[-1] - d\n",
    "    df = df[df['time']>threeMonth]\n",
    "\n",
    "    print(df.describe())\n",
    "    \n",
    "def main():\n",
    "    data = scrapeAdvanceDataList()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"{0}.csv\".format(\"dataTokenAdvance\"), sep=',', index=False)\n",
    "\n",
    "def testing():\n",
    "   \n",
    "    return \n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
